{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef1494a",
   "metadata": {},
   "source": [
    "# Fixing Kernel Issues in Elyra Pipelines\n",
    "\n",
    "This notebook demonstrates how to fix the \"No kernel name found in notebook and no override provided\" error that occurs when executing notebooks in Elyra pipelines.\n",
    "\n",
    "## Problem\n",
    "When Elyra executes notebooks via Papermill, it requires the notebook to have proper kernel metadata. If this metadata is missing, the execution fails.\n",
    "\n",
    "## Solutions\n",
    "1. Check and fix notebook metadata\n",
    "2. Set kernel name programmatically\n",
    "3. Verify kernel configuration\n",
    "4. Test with Papermill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674ee87",
   "metadata": {},
   "source": [
    "## 1. Check Notebook Kernel Information\n",
    "\n",
    "First, let's check what kernel information is present in your existing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7acd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Notebook not found: /home/jovyan/work/data_ingestion_fixed.ipynb\n",
      "Let's check what notebooks are available:\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to check kernel information in a notebook\n",
    "def check_notebook_kernel(notebook_path):\n",
    "    \"\"\"Check if a notebook has kernel information in its metadata\"\"\"\n",
    "    try:\n",
    "        with open(notebook_path, 'r') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        print(f\"üìñ Checking notebook: {os.path.basename(notebook_path)}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Check kernelspec in metadata\n",
    "        if 'kernelspec' in nb.metadata:\n",
    "            kernelspec = nb.metadata['kernelspec']\n",
    "            print(\"‚úÖ Kernelspec found:\")\n",
    "            print(f\"   Name: {kernelspec.get('name', 'Not specified')}\")\n",
    "            print(f\"   Display Name: {kernelspec.get('display_name', 'Not specified')}\")\n",
    "            print(f\"   Language: {kernelspec.get('language', 'Not specified')}\")\n",
    "        else:\n",
    "            print(\"‚ùå No kernelspec found in metadata\")\n",
    "        \n",
    "        # Check language_info\n",
    "        if 'language_info' in nb.metadata:\n",
    "            lang_info = nb.metadata['language_info']\n",
    "            print(\"\\nüìÑ Language info found:\")\n",
    "            print(f\"   Name: {lang_info.get('name', 'Not specified')}\")\n",
    "            print(f\"   Version: {lang_info.get('version', 'Not specified')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå No language_info found in metadata\")\n",
    "            \n",
    "        return nb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading notebook: {e}\")\n",
    "        return None\n",
    "\n",
    "# Check the problematic notebook\n",
    "problematic_notebook = \"/home/jovyan/work/data_ingestion_fixed.ipynb\"\n",
    "if os.path.exists(problematic_notebook):\n",
    "    nb = check_notebook_kernel(problematic_notebook)\n",
    "else:\n",
    "    print(f\"‚ùå Notebook not found: {problematic_notebook}\")\n",
    "    print(\"Let's check what notebooks are available:\")\n",
    "    for root, dirs, files in os.walk(\"/home/jovyan/work\"):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                print(f\"  üìì {os.path.join(root, file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f5f7b",
   "metadata": {},
   "source": [
    "## 2. Set Kernel Name Programmatically\n",
    "\n",
    "Now let's fix the notebook by adding the required kernel metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_notebook_kernel(notebook_path, kernel_name=\"python3\", backup=True):\n",
    "    \"\"\"Fix notebook kernel metadata to work with Elyra/Papermill\"\"\"\n",
    "    try:\n",
    "        # Create backup if requested\n",
    "        if backup:\n",
    "            backup_path = notebook_path + \".backup\"\n",
    "            with open(notebook_path, 'r') as original:\n",
    "                with open(backup_path, 'w') as backup_file:\n",
    "                    backup_file.write(original.read())\n",
    "            print(f\"üìÅ Backup created: {backup_path}\")\n",
    "        \n",
    "        # Read the notebook\n",
    "        with open(notebook_path, 'r') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        # Set kernelspec metadata\n",
    "        nb.metadata['kernelspec'] = {\n",
    "            'display_name': 'Python 3 (ipykernel)',\n",
    "            'language': 'python',\n",
    "            'name': kernel_name\n",
    "        }\n",
    "        \n",
    "        # Set language_info metadata\n",
    "        nb.metadata['language_info'] = {\n",
    "            'codemirror_mode': {\n",
    "                'name': 'ipython',\n",
    "                'version': 3\n",
    "            },\n",
    "            'file_extension': '.py',\n",
    "            'mimetype': 'text/x-python',\n",
    "            'name': 'python',\n",
    "            'nbconvert_exporter': 'python',\n",
    "            'pygments_lexer': 'ipython3',\n",
    "            'version': '3.10.0'\n",
    "        }\n",
    "        \n",
    "        # Write the fixed notebook\n",
    "        with open(notebook_path, 'w') as f:\n",
    "            nbformat.write(nb, f)\n",
    "        \n",
    "        print(f\"‚úÖ Fixed kernel metadata in: {os.path.basename(notebook_path)}\")\n",
    "        print(f\"   Kernel name set to: {kernel_name}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fixing notebook: {e}\")\n",
    "        return False\n",
    "\n",
    "# Fix the problematic notebook\n",
    "if os.path.exists(problematic_notebook):\n",
    "    success = fix_notebook_kernel(problematic_notebook)\n",
    "    if success:\n",
    "        print(\"\\nüîç Verifying the fix...\")\n",
    "        check_notebook_kernel(problematic_notebook)\n",
    "else:\n",
    "    print(\"‚ùå Cannot fix notebook - file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f659e",
   "metadata": {},
   "source": [
    "## 3. Verify Kernel Configuration\n",
    "\n",
    "Let's check what kernels are available in the Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fa06ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Available Jupyter kernels:\n",
      "==============================\n",
      "‚úÖ python3\n",
      "   Display name: Python 3 (ipykernel)\n",
      "   Language: python\n",
      "   Path: /Users/nickpeachey/Developer/python/airflow-elyra/.venv/share/jupyter/kernels/python3\n",
      "\n",
      "‚úÖ Recommended kernel 'python3' is available\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def check_available_kernels():\n",
    "    \"\"\"Check what kernels are available in the Jupyter environment\"\"\"\n",
    "    try:\n",
    "        # Get kernel specs using jupyter command\n",
    "        result = subprocess.run(['jupyter', 'kernelspec', 'list', '--json'], \n",
    "                              capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            kernels = json.loads(result.stdout)\n",
    "            print(\"üîß Available Jupyter kernels:\")\n",
    "            print(\"=\" * 30)\n",
    "            \n",
    "            for name, info in kernels['kernelspecs'].items():\n",
    "                print(f\"‚úÖ {name}\")\n",
    "                print(f\"   Display name: {info['spec']['display_name']}\")\n",
    "                print(f\"   Language: {info['spec']['language']}\")\n",
    "                print(f\"   Path: {info['resource_dir']}\")\n",
    "                print()\n",
    "                \n",
    "            return list(kernels['kernelspecs'].keys())\n",
    "        else:\n",
    "            print(f\"‚ùå Error getting kernel list: {result.stderr}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking kernels: {e}\")\n",
    "        return []\n",
    "\n",
    "# Check available kernels\n",
    "available_kernels = check_available_kernels()\n",
    "\n",
    "# Verify our kernel choice\n",
    "recommended_kernel = \"python3\"\n",
    "if recommended_kernel in available_kernels:\n",
    "    print(f\"‚úÖ Recommended kernel '{recommended_kernel}' is available\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Recommended kernel '{recommended_kernel}' not found\")\n",
    "    if available_kernels:\n",
    "        print(f\"üí° Consider using: {available_kernels[0]}\")\n",
    "    else:\n",
    "        print(\"‚ùå No kernels available - this is a problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d60c7",
   "metadata": {},
   "source": [
    "## 4. Test Notebook Execution\n",
    "\n",
    "Let's test if the fixed notebook can now be executed with Papermill (the same engine Elyra uses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import tempfile\n",
    "\n",
    "def test_notebook_execution(notebook_path):\n",
    "    \"\"\"Test if a notebook can be executed with Papermill\"\"\"\n",
    "    try:\n",
    "        # Create a temporary output path\n",
    "        with tempfile.NamedTemporaryFile(suffix='.ipynb', delete=False) as tmp:\n",
    "            output_path = tmp.name\n",
    "        \n",
    "        print(f\"üß™ Testing notebook execution...\")\n",
    "        print(f\"   Input: {os.path.basename(notebook_path)}\")\n",
    "        print(f\"   Output: {os.path.basename(output_path)}\")\n",
    "        \n",
    "        # Try to execute the notebook with papermill\n",
    "        pm.execute_notebook(\n",
    "            input_path=notebook_path,\n",
    "            output_path=output_path,\n",
    "            progress_bar=False\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Notebook executed successfully!\")\n",
    "        print(\"   The notebook is now compatible with Elyra pipelines\")\n",
    "        \n",
    "        # Clean up\n",
    "        os.unlink(output_path)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Execution failed: {e}\")\n",
    "        print(\"   This notebook still has issues that need to be resolved\")\n",
    "        return False\n",
    "\n",
    "# Test the fixed notebook\n",
    "if os.path.exists(problematic_notebook):\n",
    "    print(\"Testing the fixed notebook...\")\n",
    "    test_notebook_execution(problematic_notebook)\n",
    "else:\n",
    "    print(\"‚ùå Cannot test - notebook not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcfbc1e",
   "metadata": {},
   "source": [
    "## 5. Alternative Solutions for Kernel Issues\n",
    "\n",
    "Here are additional methods to prevent and fix kernel issues in Elyra pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kernel_ready_template(output_path):\n",
    "    \"\"\"Create a template notebook with proper kernel metadata\"\"\"\n",
    "    # Create a new notebook with proper metadata\n",
    "    nb = nbformat.v4.new_notebook()\n",
    "    \n",
    "    # Add proper metadata\n",
    "    nb.metadata.kernelspec = {\n",
    "        'display_name': 'Python 3 (ipykernel)',\n",
    "        'language': 'python',\n",
    "        'name': 'python3'\n",
    "    }\n",
    "    \n",
    "    nb.metadata.language_info = {\n",
    "        'codemirror_mode': {\n",
    "            'name': 'ipython',\n",
    "            'version': 3\n",
    "        },\n",
    "        'file_extension': '.py',\n",
    "        'mimetype': 'text/x-python',\n",
    "        'name': 'python',\n",
    "        'nbconvert_exporter': 'python',\n",
    "        'pygments_lexer': 'ipython3',\n",
    "        'version': '3.10.0'\n",
    "    }\n",
    "    \n",
    "    # Add a sample cell\n",
    "    code_cell = nbformat.v4.new_code_cell(\n",
    "        source=\"# This is a template notebook ready for Elyra pipelines\\n\"\n",
    "               \"print('Hello from Elyra-ready notebook!')\\n\"\n",
    "               \"\\n\"\n",
    "               \"# Add your code here\\n\"\n",
    "               \"# This notebook has proper kernel metadata\"\n",
    "    )\n",
    "    nb.cells.append(code_cell)\n",
    "    \n",
    "    # Write the template\n",
    "    with open(output_path, 'w') as f:\n",
    "        nbformat.write(nb, f)\n",
    "    \n",
    "    print(f\"‚úÖ Created kernel-ready template: {output_path}\")\n",
    "\n",
    "def fix_all_notebooks_in_directory(directory_path):\n",
    "    \"\"\"Fix kernel metadata for all notebooks in a directory\"\"\"\n",
    "    fixed_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"üîç Scanning directory: {directory_path}\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb') and not file.endswith('.backup'):\n",
    "                notebook_path = os.path.join(root, file)\n",
    "                print(f\"\\nüìì Processing: {file}\")\n",
    "                \n",
    "                if fix_notebook_kernel(notebook_path, backup=True):\n",
    "                    fixed_count += 1\n",
    "                else:\n",
    "                    error_count += 1\n",
    "    \n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   ‚úÖ Fixed: {fixed_count} notebooks\")\n",
    "    print(f\"   ‚ùå Errors: {error_count} notebooks\")\n",
    "\n",
    "# Create a template for future notebooks\n",
    "template_path = \"/home/jovyan/work/elyra_template.ipynb\"\n",
    "create_kernel_ready_template(template_path)\n",
    "\n",
    "# Example: Fix all notebooks in the work directory\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BATCH PROCESSING EXAMPLE\")\n",
    "print(\"=\"*50)\n",
    "work_dir = \"/home/jovyan/work\"\n",
    "if os.path.exists(work_dir):\n",
    "    fix_all_notebooks_in_directory(work_dir)\n",
    "else:\n",
    "    print(f\"‚ùå Directory not found: {work_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40ddb8",
   "metadata": {},
   "source": [
    "## Summary & Prevention Tips\n",
    "\n",
    "### ‚úÖ Quick Fix for Your Current Issue\n",
    "\n",
    "Run these steps to fix your `data_ingestion_fixed.ipynb`:\n",
    "\n",
    "1. **Check the notebook** - First cell will show what's missing\n",
    "2. **Fix the kernel metadata** - Second cell will add the required metadata  \n",
    "3. **Verify the fix** - Third cell will confirm it's working\n",
    "4. **Test with Papermill** - Fourth cell will simulate Elyra execution\n",
    "\n",
    "### üõ°Ô∏è Prevention Tips\n",
    "\n",
    "**For new notebooks:**\n",
    "- Always create notebooks in JupyterLab (they get proper metadata automatically)\n",
    "- Use the template created in cell 5 as a starting point\n",
    "- Copy kernel metadata from working notebooks\n",
    "\n",
    "**For existing notebooks:**\n",
    "- Run the batch fix function (cell 5) on your notebook directory\n",
    "- Always backup before making changes\n",
    "- Test with Papermill before using in Elyra pipelines\n",
    "\n",
    "### üîß What Fixed the Issue\n",
    "\n",
    "The error occurs because Elyra uses Papermill to execute notebooks, and Papermill requires:\n",
    "1. `kernelspec` metadata with the kernel name\n",
    "2. `language_info` metadata for proper execution context\n",
    "\n",
    "Without these, Papermill can't determine which kernel to use for execution.\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "After running this notebook:\n",
    "1. Try your Elyra pipeline again - it should work now!\n",
    "2. Use the created template for new notebooks\n",
    "3. Consider running the batch fix on all your existing notebooks\n",
    "\n",
    "---\n",
    "**Happy pipeline building with Elyra! üéâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105417e",
   "metadata": {},
   "source": [
    "## üöÄ Quick Fix for Your Specific Error\n",
    "\n",
    "Run this cell to fix your `data_ingestion_fixed.ipynb` notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162550c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for your notebook...\n",
      "‚úÖ Found notebook at: data_ingestion_fixed.ipynb\n",
      "\n",
      "üîß Fixing kernel metadata in: data_ingestion_fixed.ipynb\n",
      "üìÅ Backup created: data_ingestion_fixed.ipynb.backup\n",
      "‚úÖ FIXED! Your notebook now has proper kernel metadata\n",
      "üéâ You can now use it in Elyra pipelines!\n"
     ]
    }
   ],
   "source": [
    "# QUICK FIX: Update this path to match your actual notebook location\n",
    "your_notebook_path = \"data_ingestion_fixed.ipynb\"  # Update this path!\n",
    "\n",
    "# Alternative common locations to check\n",
    "possible_paths = [\n",
    "    \"data_ingestion_fixed.ipynb\",\n",
    "    \"notebooks/data_ingestion_fixed.ipynb\", \n",
    "    \"../data_ingestion_fixed.ipynb\",\n",
    "    \"/home/jovyan/work/data_ingestion_fixed.ipynb\",\n",
    "    \"./data_ingestion_fixed.ipynb\"\n",
    "]\n",
    "\n",
    "print(\"üîç Searching for your notebook...\")\n",
    "found_notebook = None\n",
    "\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        found_notebook = path\n",
    "        print(f\"‚úÖ Found notebook at: {path}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"‚ùå Not found: {path}\")\n",
    "\n",
    "if found_notebook:\n",
    "    print(f\"\\nüîß Fixing kernel metadata in: {found_notebook}\")\n",
    "    \n",
    "    # Read the notebook\n",
    "    with open(found_notebook, 'r') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Backup original\n",
    "    backup_path = found_notebook + \".backup\"\n",
    "    with open(backup_path, 'w') as f:\n",
    "        nbformat.write(nb, f)\n",
    "    print(f\"üìÅ Backup created: {backup_path}\")\n",
    "    \n",
    "    # Fix the metadata\n",
    "    nb.metadata['kernelspec'] = {\n",
    "        'display_name': 'Python 3 (ipykernel)',\n",
    "        'language': 'python', \n",
    "        'name': 'python3'\n",
    "    }\n",
    "    \n",
    "    nb.metadata['language_info'] = {\n",
    "        'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
    "        'file_extension': '.py',\n",
    "        'mimetype': 'text/x-python',\n",
    "        'name': 'python',\n",
    "        'nbconvert_exporter': 'python',\n",
    "        'pygments_lexer': 'ipython3',\n",
    "        'version': '3.10.0'\n",
    "    }\n",
    "    \n",
    "    # Save the fixed notebook\n",
    "    with open(found_notebook, 'w') as f:\n",
    "        nbformat.write(nb, f)\n",
    "    \n",
    "    print(\"‚úÖ FIXED! Your notebook now has proper kernel metadata\")\n",
    "    print(\"üéâ You can now use it in Elyra pipelines!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå Notebook not found in common locations.\")\n",
    "    print(\"üí° Please update the 'your_notebook_path' variable above with the correct path.\")\n",
    "    print(\"   You can find the exact path by checking your Elyra pipeline editor.\")\n",
    "    \n",
    "    # Show current directory contents\n",
    "    print(f\"\\nüìÇ Current directory contents:\")\n",
    "    for item in os.listdir('.'):\n",
    "        if item.endswith('.ipynb'):\n",
    "            print(f\"   üìì {item}\")\n",
    "        elif os.path.isdir(item):\n",
    "            print(f\"   üìÅ {item}/\")\n",
    "            \n",
    "    print(f\"\\nüíª Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c2712",
   "metadata": {},
   "source": [
    "## üêã Configure Kubernetes Runtime for Elyra\n",
    "\n",
    "Elyra needs runtime configurations to execute pipelines on Kubernetes. Let's set up the Kubernetes runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39833c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker: Configuring Kubernetes runtime for custom Docker image...\n",
      "   Image: jupyter-elyra:latest\n",
      "   This image already has Elyra pre-installed with all dependencies\n",
      "\n",
      "Info: The runtime configuration will use our custom image for pipeline execution\n",
      "   No need to install Elyra locally - it's already in the Docker image!\n"
     ]
    }
   ],
   "source": [
    "# Configure runtime for the custom Docker image we built\n",
    "print(\"Docker: Configuring Kubernetes runtime for custom Docker image...\")\n",
    "print(\"   Image: jupyter-elyra:latest\")\n",
    "print(\"   This image already has Elyra pre-installed with all dependencies\")\n",
    "print()\n",
    "print(\"Info: The runtime configuration will use our custom image for pipeline execution\")\n",
    "print(\"   No need to install Elyra locally - it's already in the Docker image!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f52294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating Kubernetes runtime configuration...\n",
      "   Using custom Docker image: jupyter-elyra:latest\n",
      "\n",
      "üìÅ Creating runtime configuration files:\n",
      "   ‚úÖ kubernetes-kubeflow.json\n",
      "   ‚úÖ kubernetes-local.json\n",
      "   ‚úÖ kubernetes-airflow.json\n",
      "\n",
      "üéØ Runtime Configuration Summary:\n",
      "==================================================\n",
      "\n",
      "üìã Kubernetes Cluster (KFP)\n",
      "   File: kubernetes-kubeflow.json\n",
      "   Schema: kfp\n",
      "   Image: jupyter-elyra:latest\n",
      "   Endpoint: http://localhost:8080/pipeline\n",
      "\n",
      "üìã Local Docker (Custom Image)\n",
      "   File: kubernetes-local.json\n",
      "   Schema: local\n",
      "   Image: jupyter-elyra:latest\n",
      "\n",
      "üìã Airflow (Custom Image)\n",
      "   File: kubernetes-airflow.json\n",
      "   Schema: airflow\n",
      "   Image: jupyter-elyra:latest\n",
      "   Endpoint: http://localhost:8080\n",
      "\n",
      "üîç Next Steps:\n",
      "1. Open Elyra in your Jupyter environment\n",
      "2. Go to the Runtime Images configuration\n",
      "3. Import these JSON files or create runtimes manually\n",
      "4. Use the 'jupyter-elyra:latest' image for all runtimes\n",
      "\n",
      "üéâ Runtime configuration files created!\n",
      "üí° Your custom Docker image is ready for Kubernetes pipeline execution\n",
      "üê≥ The image contains: Elyra + PySpark + Kubernetes client + all dependencies\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def create_kubernetes_runtime_config():\n",
    "    \"\"\"Create Kubernetes runtime configuration files for the custom Docker image\"\"\"\n",
    "    \n",
    "    print(\"üîß Creating Kubernetes runtime configuration...\")\n",
    "    print(\"   Using custom Docker image: jupyter-elyra:latest\")\n",
    "    print()\n",
    "    \n",
    "    # Kubernetes runtime configuration for Kubeflow Pipelines\n",
    "    kfp_config = {\n",
    "        \"display_name\": \"Kubernetes Cluster (KFP)\",\n",
    "        \"schema_name\": \"kfp\",\n",
    "        \"metadata\": {\n",
    "            \"api_endpoint\": \"http://localhost:8080/pipeline\",  # Kubeflow Pipelines endpoint\n",
    "            \"cos_endpoint\": \"http://minio:9000\",  # MinIO object storage\n",
    "            \"cos_username\": \"minio\",\n",
    "            \"cos_password\": \"minio123\", \n",
    "            \"cos_bucket\": \"mlpipeline\",\n",
    "            \"cos_auth_type\": \"USER_CREDENTIALS\",\n",
    "            \"engine\": \"Argo\",\n",
    "            \"kubernetes_pod_annotations\": {},\n",
    "            \"kubernetes_pod_labels\": {},\n",
    "            \"kubernetes_tolerations\": {},\n",
    "            \"kubernetes_shared_mem_size\": {},\n",
    "            \"mount_volumes\": {},\n",
    "            \"env_vars\": {},\n",
    "            \"runtime_image\": \"jupyter-elyra:latest\"  # Our custom image with Elyra pre-installed\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Local runtime configuration using custom image\n",
    "    local_config = {\n",
    "        \"display_name\": \"Local Docker (Custom Image)\",\n",
    "        \"schema_name\": \"local\",\n",
    "        \"metadata\": {\n",
    "            \"runtime_image\": \"jupyter-elyra:latest\",\n",
    "            \"cos_endpoint\": \"\",\n",
    "            \"cos_username\": \"\",\n",
    "            \"cos_password\": \"\",\n",
    "            \"cos_bucket\": \"\",\n",
    "            \"cos_auth_type\": \"NO_CREDENTIALS\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Airflow runtime configuration\n",
    "    airflow_config = {\n",
    "        \"display_name\": \"Airflow (Custom Image)\",\n",
    "        \"schema_name\": \"airflow\",\n",
    "        \"metadata\": {\n",
    "            \"api_endpoint\": \"http://localhost:8080\",  # Airflow webserver\n",
    "            \"cos_endpoint\": \"http://minio:9000\",\n",
    "            \"cos_username\": \"minio\",\n",
    "            \"cos_password\": \"minio123\",\n",
    "            \"cos_bucket\": \"airflow-logs\",\n",
    "            \"cos_auth_type\": \"USER_CREDENTIALS\",\n",
    "            \"runtime_image\": \"jupyter-elyra:latest\",\n",
    "            \"namespace\": \"default\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save configurations as JSON files that can be imported into Elyra\n",
    "    configs = {\n",
    "        \"kubernetes-kubeflow.json\": kfp_config,\n",
    "        \"kubernetes-local.json\": local_config,\n",
    "        \"kubernetes-airflow.json\": airflow_config\n",
    "    }\n",
    "    \n",
    "    print(\"üìÅ Creating runtime configuration files:\")\n",
    "    for filename, config in configs.items():\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        print(f\"   ‚úÖ {filename}\")\n",
    "    \n",
    "    print(\"\\nüéØ Runtime Configuration Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for name, config in configs.items():\n",
    "        print(f\"\\nüìã {config['display_name']}\")\n",
    "        print(f\"   File: {name}\")\n",
    "        print(f\"   Schema: {config['schema_name']}\")\n",
    "        print(f\"   Image: {config['metadata']['runtime_image']}\")\n",
    "        if config['metadata'].get('api_endpoint'):\n",
    "            print(f\"   Endpoint: {config['metadata']['api_endpoint']}\")\n",
    "    \n",
    "    print(\"\\nüîç Next Steps:\")\n",
    "    print(\"1. Open Elyra in your Jupyter environment\")\n",
    "    print(\"2. Go to the Runtime Images configuration\")\n",
    "    print(\"3. Import these JSON files or create runtimes manually\")\n",
    "    print(\"4. Use the 'jupyter-elyra:latest' image for all runtimes\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Create the runtime configurations\n",
    "success = create_kubernetes_runtime_config()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nüéâ Runtime configuration files created!\")\n",
    "    print(\"üí° Your custom Docker image is ready for Kubernetes pipeline execution\")\n",
    "    print(\"üê≥ The image contains: Elyra + PySpark + Kubernetes client + all dependencies\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to create runtime configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd2ef3",
   "metadata": {},
   "source": [
    "### üéØ Manual Runtime Configuration for Custom Docker Image\n",
    "\n",
    "Since you have a custom Docker image with Elyra pre-installed, configure runtimes manually:\n",
    "\n",
    "#### üê≥ Using Your Custom Image: `jupyter-elyra:latest`\n",
    "\n",
    "1. **Open Elyra Runtime Configuration:**\n",
    "   - In your Jupyter environment, click the Elyra icon (pipeline) in the left sidebar\n",
    "   - Click on \"Runtimes\" or \"Runtime Images\"\n",
    "   - Click the \"+\" button to add a new runtime\n",
    "\n",
    "2. **Create Local Runtime (Recommended for testing):**\n",
    "   ```\n",
    "   Name: local-custom\n",
    "   Display Name: Local Docker (Custom Image)\n",
    "   Runtime Image: jupyter-elyra:latest\n",
    "   ```\n",
    "\n",
    "3. **Create Kubernetes Runtime (for cluster execution):**\n",
    "   ```\n",
    "   Name: kubernetes-custom\n",
    "   Display Name: Kubernetes (Custom Image)  \n",
    "   Runtime Image: jupyter-elyra:latest\n",
    "   Kubeflow Pipeline Endpoint: http://localhost:8080/pipeline\n",
    "   Object Storage Endpoint: http://minio:9000\n",
    "   Object Storage Username: minio\n",
    "   Object Storage Password: minio123\n",
    "   Object Storage Bucket: mlpipeline\n",
    "   ```\n",
    "\n",
    "4. **Create Airflow Runtime (for your setup):**\n",
    "   ```\n",
    "   Name: airflow-custom\n",
    "   Display Name: Airflow (Custom Image)\n",
    "   Runtime Image: jupyter-elyra:latest\n",
    "   Apache Airflow Endpoint: http://localhost:8080\n",
    "   Object Storage Endpoint: http://minio:9000\n",
    "   Object Storage Bucket: airflow-logs\n",
    "   ```\n",
    "\n",
    "#### ‚úÖ Verification Steps:\n",
    "\n",
    "1. **Check Runtime Availability:**\n",
    "   - Go to Pipeline Editor\n",
    "   - Create a new pipeline\n",
    "   - Verify your custom runtimes appear in the dropdown\n",
    "\n",
    "2. **Test Pipeline Execution:**\n",
    "   - Use the fixed notebooks from this session\n",
    "   - Create a simple pipeline\n",
    "   - Execute using your custom runtime\n",
    "\n",
    "#### üîß Key Benefits of Custom Image:\n",
    "\n",
    "- ‚úÖ Elyra pre-installed and configured\n",
    "- ‚úÖ All dependencies resolved (no version conflicts)\n",
    "- ‚úÖ PySpark + Kubernetes client ready\n",
    "- ‚úÖ Consistent execution environment\n",
    "- ‚úÖ No installation delays during pipeline execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
