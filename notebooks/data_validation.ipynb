{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16157b16",
   "metadata": {},
   "source": [
    "# Data Validation Notebook\n",
    "\n",
    "This notebook performs data quality validation on processed data.\n",
    "\n",
    "## Parameters\n",
    "- `execution_date`: Date of pipeline execution\n",
    "- `s3_bucket`: S3 bucket containing processed data\n",
    "- `aws_endpoint_url`: AWS endpoint URL (LocalStack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809451db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters - these will be injected by Papermill\n",
    "execution_date = '2024-01-01'\n",
    "s3_bucket = 'processed-data'\n",
    "aws_endpoint_url = 'http://localhost:4566'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Configure AWS credentials for LocalStack\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'test'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'test'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "print(f\"Execution Date: {execution_date}\")\n",
    "print(f\"S3 Bucket: {s3_bucket}\")\n",
    "print(f\"AWS Endpoint: {aws_endpoint_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=aws_endpoint_url,\n",
    "    aws_access_key_id='test',\n",
    "    aws_secret_access_key='test',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "# List objects in the processed data bucket\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=s3_bucket)\n",
    "    if 'Contents' in response:\n",
    "        print(f\"Found {len(response['Contents'])} objects in bucket:\")\n",
    "        for obj in response['Contents'][:10]:  # Show first 10\n",
    "            print(f\"  - {obj['Key']} ({obj['Size']} bytes)\")\n",
    "    else:\n",
    "        print(\"No objects found in bucket\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing bucket contents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data quality rules\n",
    "data_quality_rules = {\n",
    "    'completeness': {\n",
    "        'description': 'Check for missing values',\n",
    "        'threshold': 0.05  # Max 5% missing values allowed\n",
    "    },\n",
    "    'uniqueness': {\n",
    "        'description': 'Check for duplicate records',\n",
    "        'threshold': 0.01  # Max 1% duplicates allowed\n",
    "    },\n",
    "    'validity': {\n",
    "        'description': 'Check data format and ranges',\n",
    "        'rules': {\n",
    "            'amount': {'min': 0, 'max': 10000},\n",
    "            'customer_id': {'min': 1}\n",
    "        }\n",
    "    },\n",
    "    'consistency': {\n",
    "        'description': 'Check referential integrity',\n",
    "        'rules': {\n",
    "            'category': ['Electronics', 'Clothing', 'Food', 'Books', 'Other'],\n",
    "            'payment_method': ['Credit Card', 'Debit Card', 'Cash', 'PayPal']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Data Quality Rules:\")\n",
    "for rule_name, rule_config in data_quality_rules.items():\n",
    "    print(f\"  {rule_name}: {rule_config['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's create some sample processed data\n",
    "# In a real scenario, this would be read from S3\n",
    "np.random.seed(42)\n",
    "n_records = 9500  # Simulating some data loss during processing\n",
    "\n",
    "processed_data = pd.DataFrame({\n",
    "    'customer_id': range(1, n_records + 1),\n",
    "    'transaction_date': pd.date_range(\n",
    "        start=execution_date, \n",
    "        periods=n_records, \n",
    "        freq='min'\n",
    "    ),\n",
    "    'amount': np.random.normal(100, 25, n_records),\n",
    "    'category': np.random.choice(\n",
    "        ['Electronics', 'Clothing', 'Food', 'Books', 'Other'], \n",
    "        n_records\n",
    "    ),\n",
    "    'payment_method': np.random.choice(\n",
    "        ['Credit Card', 'Debit Card', 'Cash', 'PayPal'], \n",
    "        n_records\n",
    "    )\n",
    "})\n",
    "\n",
    "# Add some data quality issues for testing\n",
    "processed_data.loc[0:10, 'amount'] = np.nan  # Missing values\n",
    "processed_data = pd.concat([processed_data, processed_data.iloc[0:5]])  # Duplicates\n",
    "processed_data.loc[20, 'amount'] = -100  # Invalid amount\n",
    "processed_data.loc[21, 'category'] = 'InvalidCategory'  # Invalid category\n",
    "\n",
    "print(f\"Loaded {len(processed_data)} records for validation\")\n",
    "print(processed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c2778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Results Storage\n",
    "validation_results = {\n",
    "    'execution_date': execution_date,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_records': len(processed_data),\n",
    "    'tests': {}\n",
    "}\n",
    "\n",
    "# Test 1: Completeness\n",
    "print(\"=== Completeness Test ===\")\n",
    "missing_data = processed_data.isnull().sum()\n",
    "missing_percentage = (missing_data / len(processed_data)) * 100\n",
    "\n",
    "completeness_passed = True\n",
    "for column, missing_pct in missing_percentage.items():\n",
    "    threshold_pct = data_quality_rules['completeness']['threshold'] * 100\n",
    "    status = \"PASS\" if missing_pct <= threshold_pct else \"FAIL\"\n",
    "    if status == \"FAIL\":\n",
    "        completeness_passed = False\n",
    "    print(f\"  {column}: {missing_pct:.2f}% missing ({status})\")\n",
    "\n",
    "validation_results['tests']['completeness'] = {\n",
    "    'passed': completeness_passed,\n",
    "    'missing_data': missing_data.to_dict(),\n",
    "    'missing_percentage': missing_percentage.to_dict()\n",
    "}\n",
    "\n",
    "print(f\"\\nCompleteness Test: {'PASSED' if completeness_passed else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f309c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Uniqueness\n",
    "print(\"\\n=== Uniqueness Test ===\")\n",
    "total_records = len(processed_data)\n",
    "unique_records = len(processed_data.drop_duplicates())\n",
    "duplicate_count = total_records - unique_records\n",
    "duplicate_percentage = (duplicate_count / total_records) * 100\n",
    "\n",
    "threshold_pct = data_quality_rules['uniqueness']['threshold'] * 100\n",
    "uniqueness_passed = duplicate_percentage <= threshold_pct\n",
    "\n",
    "print(f\"  Total records: {total_records}\")\n",
    "print(f\"  Unique records: {unique_records}\")\n",
    "print(f\"  Duplicates: {duplicate_count} ({duplicate_percentage:.2f}%)\")\n",
    "print(f\"  Status: {'PASS' if uniqueness_passed else 'FAIL'}\")\n",
    "\n",
    "validation_results['tests']['uniqueness'] = {\n",
    "    'passed': uniqueness_passed,\n",
    "    'total_records': total_records,\n",
    "    'unique_records': unique_records,\n",
    "    'duplicate_count': duplicate_count,\n",
    "    'duplicate_percentage': duplicate_percentage\n",
    "}\n",
    "\n",
    "print(f\"\\nUniqueness Test: {'PASSED' if uniqueness_passed else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Validity (Range checks)\n",
    "print(\"\\n=== Validity Test ===\")\n",
    "validity_results = {}\n",
    "validity_passed = True\n",
    "\n",
    "# Check amount ranges\n",
    "amount_rules = data_quality_rules['validity']['rules']['amount']\n",
    "invalid_amounts = processed_data[\n",
    "    (processed_data['amount'] < amount_rules['min']) | \n",
    "    (processed_data['amount'] > amount_rules['max'])\n",
    "]\n",
    "amount_valid = len(invalid_amounts) == 0\n",
    "if not amount_valid:\n",
    "    validity_passed = False\n",
    "\n",
    "print(f\"  Amount range check: {'PASS' if amount_valid else 'FAIL'}\")\n",
    "if not amount_valid:\n",
    "    print(f\"    Invalid amounts found: {len(invalid_amounts)}\")\n",
    "\n",
    "validity_results['amount_range'] = {\n",
    "    'passed': amount_valid,\n",
    "    'invalid_count': len(invalid_amounts)\n",
    "}\n",
    "\n",
    "# Check customer_id\n",
    "customer_id_rules = data_quality_rules['validity']['rules']['customer_id']\n",
    "invalid_customer_ids = processed_data[\n",
    "    processed_data['customer_id'] < customer_id_rules['min']\n",
    "]\n",
    "customer_id_valid = len(invalid_customer_ids) == 0\n",
    "if not customer_id_valid:\n",
    "    validity_passed = False\n",
    "\n",
    "print(f\"  Customer ID check: {'PASS' if customer_id_valid else 'FAIL'}\")\n",
    "\n",
    "validity_results['customer_id'] = {\n",
    "    'passed': customer_id_valid,\n",
    "    'invalid_count': len(invalid_customer_ids)\n",
    "}\n",
    "\n",
    "validation_results['tests']['validity'] = {\n",
    "    'passed': validity_passed,\n",
    "    'details': validity_results\n",
    "}\n",
    "\n",
    "print(f\"\\nValidity Test: {'PASSED' if validity_passed else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Consistency (Categorical values)\n",
    "print(\"\\n=== Consistency Test ===\")\n",
    "consistency_results = {}\n",
    "consistency_passed = True\n",
    "\n",
    "# Check category values\n",
    "valid_categories = data_quality_rules['consistency']['rules']['category']\n",
    "invalid_categories = processed_data[\n",
    "    ~processed_data['category'].isin(valid_categories)\n",
    "]\n",
    "category_consistent = len(invalid_categories) == 0\n",
    "if not category_consistent:\n",
    "    consistency_passed = False\n",
    "\n",
    "print(f\"  Category consistency: {'PASS' if category_consistent else 'FAIL'}\")\n",
    "if not category_consistent:\n",
    "    print(f\"    Invalid categories: {invalid_categories['category'].unique()}\")\n",
    "\n",
    "consistency_results['category'] = {\n",
    "    'passed': category_consistent,\n",
    "    'invalid_count': len(invalid_categories)\n",
    "}\n",
    "\n",
    "# Check payment method values\n",
    "valid_payment_methods = data_quality_rules['consistency']['rules']['payment_method']\n",
    "invalid_payment_methods = processed_data[\n",
    "    ~processed_data['payment_method'].isin(valid_payment_methods)\n",
    "]\n",
    "payment_method_consistent = len(invalid_payment_methods) == 0\n",
    "if not payment_method_consistent:\n",
    "    consistency_passed = False\n",
    "\n",
    "print(f\"  Payment method consistency: {'PASS' if payment_method_consistent else 'FAIL'}\")\n",
    "\n",
    "consistency_results['payment_method'] = {\n",
    "    'passed': payment_method_consistent,\n",
    "    'invalid_count': len(invalid_payment_methods)\n",
    "}\n",
    "\n",
    "validation_results['tests']['consistency'] = {\n",
    "    'passed': consistency_passed,\n",
    "    'details': consistency_results\n",
    "}\n",
    "\n",
    "print(f\"\\nConsistency Test: {'PASSED' if consistency_passed else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall validation summary\n",
    "all_tests = validation_results['tests']\n",
    "overall_passed = all(test['passed'] for test in all_tests.values())\n",
    "\n",
    "validation_results['overall_status'] = 'PASSED' if overall_passed else 'FAILED'\n",
    "validation_results['tests_summary'] = {\n",
    "    'total_tests': len(all_tests),\n",
    "    'passed_tests': sum(1 for test in all_tests.values() if test['passed']),\n",
    "    'failed_tests': sum(1 for test in all_tests.values() if not test['passed'])\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA QUALITY VALIDATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Execution Date: {execution_date}\")\n",
    "print(f\"Total Records: {validation_results['total_records']}\")\n",
    "print(f\"Overall Status: {validation_results['overall_status']}\")\n",
    "print(f\"Tests Passed: {validation_results['tests_summary']['passed_tests']}/{validation_results['tests_summary']['total_tests']}\")\n",
    "print()\n",
    "\n",
    "for test_name, test_result in all_tests.items():\n",
    "    status = \"✅ PASSED\" if test_result['passed'] else \"❌ FAILED\"\n",
    "    print(f\"  {test_name.title()}: {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5074fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation results\n",
    "results_json = json.dumps(validation_results, indent=2)\n",
    "results_filename = f\"validation_results_{execution_date.replace('-', '_')}.json\"\n",
    "results_path = f\"/tmp/{results_filename}\"\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    f.write(results_json)\n",
    "\n",
    "print(f\"Validation results saved to: {results_path}\")\n",
    "\n",
    "# Upload results to S3\n",
    "try:\n",
    "    s3_key = f\"validation-results/{execution_date}/{results_filename}\"\n",
    "    s3_client.upload_file(results_path, s3_bucket, s3_key)\n",
    "    print(f\"Results uploaded to S3: s3://{s3_bucket}/{s3_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading results to S3: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13bfda",
   "metadata": {},
   "source": [
    "## Validation Complete\n",
    "\n",
    "The data quality validation has been completed. The results have been saved and uploaded to S3.\n",
    "\n",
    "### Key Findings:\n",
    "- **Data Volume**: Processing completed with minimal data loss\n",
    "- **Missing Values**: Some missing values detected (expected for raw data)\n",
    "- **Duplicates**: A few duplicate records found (may need deduplication)\n",
    "- **Invalid Values**: Some outliers detected (may need further investigation)\n",
    "- **Categorical Integrity**: Most categorical values are valid\n",
    "\n",
    "### Recommendations:\n",
    "1. Implement automated alerts for failed validations\n",
    "2. Add data profiling for statistical anomaly detection\n",
    "3. Consider implementing data lineage tracking\n",
    "4. Set up monitoring dashboards for data quality metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
